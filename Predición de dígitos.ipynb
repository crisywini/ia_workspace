{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombres\n",
    "### Luisa Fernanda Cotte Sánchez y Cristian Giovanny Sánchez Pineda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga de dataset\n",
    "digitos = datasets.load_digits()\n",
    "X = digitos['data']\n",
    "t = digitos['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Analice la información que se encuentra en $X$ y $t$. ¿Qué debemos realizar, una regresión o una clasificación? Cómo se podría ajustar a una clasificación o a una regresión, argumente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X:  (1797, 64)\n",
      "Forma de t:  (1797,)\n",
      "Posibles datos de t:  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "Descripción del DATASET\n",
      ":  .. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "print('Forma de X: ',X.shape)\n",
    "print('Forma de t: ',t.shape)\n",
    "no_repeated_target = set(t) \n",
    "print('Posibles datos de t: ',no_repeated_target)\n",
    "print('Descripción del DATASET\\n: ',digitos['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe realizar una clasificación, debido a que los datos se ajustan mejor a la clasificación teniendo en cuenta que cada fila de la matriz X corresponde a características visuales de un dígito del 0 al 9, mientras que con la regresión se pretende estimar un nuevo $'Digito'$ por lo tanto, la regresión no es considerada para este trabajo. \n",
    "\n",
    "La clasificación se puede realizar con un algoritmo supervisado con los datos de la matriz X y el vector t, ya que la posicón $i$ (filas) de la matriz X tiene como clasificación la posición $i$ del vector t, es decir, se tiene un dataset etiquetado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Desarrolle una función que simule el $holdout$ $method$. El porcentaje de $X$ que se va a usar para entrenar debe estar parametrizado. No debe usar niguna dependecia a parte de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, t, percentage_train):\n",
    "    '''\n",
    "        Este método permite particionar el X en un porcentaje percentage_traing\n",
    "        para los números aleatorios basado en: https://pybonacci.org/2013/01/11/numeros-aleatorios-en-python-con-numpy-y-scipy/\n",
    "    '''\n",
    "    len_train = int(percentage_train*len(X))\n",
    "    len_test = len(X)-len_train\n",
    "    indexes = np.arange(len(X))\n",
    "    indexes_train = np.random.choice(indexes, len_train, replace=False)\n",
    "    indexes_left = set(indexes) - set(indexes_train)\n",
    "    indexes_left = np.array(list(indexes_left))\n",
    "    indexes_test = indexes_left\n",
    "   \n",
    "    X_train = np.zeros((len_train, len(X[0])))\n",
    "    t_train = np.zeros(len_train)\n",
    "    X_test = np.zeros((len_test, len(X[0])))\n",
    "    t_test = np.zeros(len_test)\n",
    "    for i in range(len(X_train)):\n",
    "        t_train[i] = t[indexes_train[i]]\n",
    "        X_train[i] = X[indexes_train[i]]\n",
    "    for i in range(len(X_test)):\n",
    "        t_test[i] = t[indexes_test[i]]\n",
    "        X_test[i] = X[indexes_test[i]]\n",
    "        \n",
    "    return X_train, t_train, X_test, t_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Usando la función desarrollada en el punto 2, divida los datos con el 70% para entrenar y el 30% para prueba. Use la dependencia de RNA para clasificar, entrenar y predecir usando tanto el conjunto de entrenamiento como el de pruebas. Use como solver sgd y como función de activación la función logística.\n",
    "Usando accuracy_score determine la exactitud para t de entrenamiento y t de pruebas <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\">Ver</a>.\n",
    "\n",
    "¿Qué resultados obtuvo, intérprete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, t_train, X_test, t_test = split_data(X, t,0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier(random_state=3, max_iter=10000, solver='sgd', activation='logistic', verbose=False).fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud entrenamiento: 0.9976133651551312\n",
      "Exactitud en pruebas: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "predictions_training1 = classifier.predict(X_train)\n",
    "score_training1 = accuracy_score(t_train, predictions_training1)\n",
    "\n",
    "predictions_test1 = classifier.predict(X_test)\n",
    "score_test1 = accuracy_score(t_test, predictions_test1)\n",
    "\n",
    "print('Exactitud entrenamiento: '+str(score_training1))\n",
    "print('Exactitud en pruebas: '+str(score_test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La evaluación del clasificador se realizó con los datos de entrenamiento y con los datos de testeo, por lo que el resultado de la exactitud para el testeo con los datos de entrenmiento fue casi del 1 lo cual es esperado porque testeo con lo mismo que entrenó, aunque la evaluación con el de pruebas, fue del 0.97, es un resultado que permite decir que el clasificador tiene un reconocimiento muy aproximado de los digitos con las características del dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Siga los siguientes pasos:\n",
    "* Use Normalizer para normalizar el conjunto de entrenamiento <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html\">Ver</a>.\n",
    "* Use train_test_split para armar el conjunto de entrenamiento y el conjunto de pruebas. Use 70% para entrenar y 30% para pruebas <a href=\"https://scikit-learn.org/stable/modules/cross_validation.html#\">Ver</a>.\n",
    "* Use una red neuronal con parámetros que desee, para generar un buen modelo <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\">Ver</a>.\n",
    "* Prediga los resultados para t de entrenamiento y t de pruebas. Usando accuracy_score determine la exactitud para t de entrenamiento y t de pruebas <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\">Ver</a>. \n",
    "* ¿Qué resultados obtuvo? Interprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Exactitud entrenamiento: 0.9554494828957836\n",
      "Exactitud en pruebas: 0.937037037037037\n"
     ]
    }
   ],
   "source": [
    "#t_normalized = Normalizer().fit_transform(t)\n",
    "transformer = Normalizer(norm='max', copy=False).fit(X)\n",
    "X_normalized = transformer.transform(X)\n",
    "#np.random.seed(1)\n",
    "X_train2, X_test2, t_train2,  t_test2 = train_test_split(X_normalized, t, test_size=0.3)\n",
    "classifier2 = MLPClassifier(max_iter=4000, solver='sgd', activation='logistic', verbose=False, random_state=3 ).fit(X_train2, t_train2)\n",
    "\n",
    "predictions_training2 = classifier2.predict(X_train2)\n",
    "score_training2 = accuracy_score(t_train2, predictions_training2)\n",
    "\n",
    "predictions_test2 = classifier2.predict(X_test2)\n",
    "score_test2 = accuracy_score(t_test2, predictions_test2)\n",
    "print('\\n')\n",
    "print('Exactitud entrenamiento: '+str(score_training2))\n",
    "print('Exactitud en pruebas: '+str(score_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar la normalización de los datos, se obtuvo un resultado menor al anterior, sin embargo no necesariamente muy bajo para considerarlo un clasificador malo. La $normalización$ y el uso del $train-test-split$ afectó los resultados ya que la confiugración del clasificador fue practicamente la misma, sin tener en cuenta que se agregó el argumento $3$ al parámetro $random-state$ el cual permite poner una semilla dentro del algoritmo de clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Ahora usando cross_val_score con un cv = 7 (<a href=\"https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics\">Ver</a>), ajuste un buen modelo ¿Qué resultados obtuvo? Interprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.87937743 0.94163424 0.88326848 0.93385214 0.95330739 0.91015625\n",
      " 0.8828125 ]\n",
      "Promedio de Scores:  0.9120583483879934\n"
     ]
    }
   ],
   "source": [
    "scores_cv = cross_val_score(classifier, X, t, cv=7)\n",
    "print('Scores: ',scores_cv)\n",
    "mean_score1 = scores_cv.mean()\n",
    "print('Promedio de Scores: ', mean_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.87937743 0.94163424 0.88326848 0.93385214 0.95330739 0.91015625\n",
      " 0.8828125 ]\n",
      "Promedio de Scores:  0.9120583483879934\n"
     ]
    }
   ],
   "source": [
    "scores_cv2 = cross_val_score(classifier2, X_normalized, t, cv=7)\n",
    "print('Scores: ',scores_cv2)\n",
    "mean_score2 = scores_cv2.mean()\n",
    "print('Promedio de Scores: ', mean_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generó los mismos resultados tanto con el clasificador con los datos iniciales, y con el clasificador con los datos normalizados, de esto se puede decir que no afectó la configuración del $random-state$ en el clasificador 2 ya que como el algoritmo validación cruzada entrena y testea con la cantidad de slots $cv$ que se le pasen por parámetro, significa que los datos por mas de que sean normalizados, no genera un cambio significativo en la respuesta del clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
